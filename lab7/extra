Q2
# --- L1 Regularization Utilities ---

def train_l1_prox(m, train_dl, val_dl, crit, opt, epochs=5, l1_lambda=1e-4, dev='cpu'):
    m.to(dev)
    history = {'loss':[], 'acc':[]}
    for e in range(epochs):
        m.train(); tot=0; corr=0; ls=0
        for X, y in train_dl:
            X, y = X.to(dev), y.to(dev)
            opt.zero_grad()
            out = m(X)
            loss = crit(out, y)
            loss.backward(); opt.step()
            # Proximal (soft-thresholding) update
            with torch.no_grad():
                for p in m.parameters():
                    p.copy_(torch.sign(p) * torch.clamp(p.abs() - opt.param_groups[0]['lr'] * l1_lambda, min=0.0))
            ls += loss.item() * X.size(0)
            tot += y.size(0)
            corr += (out.argmax(1) == y).sum().item()
        epoch_loss = ls / tot
        epoch_acc = corr / tot
        history['loss'].append(epoch_loss)
        history['acc'].append(epoch_acc)
        print(f"[Prox-L1] Epoch {e+1}: Loss={epoch_loss:.4f}, Acc={epoch_acc:.4f}")
    return history

def train_l1_manual(m, train_dl, val_dl, crit, opt, epochs=5, l1_lambda=1e-4, dev='cpu'):
    m.to(dev)
    history = {'loss':[], 'acc':[]}
    for e in range(epochs):
        m.train(); tot=0; corr=0; ls=0
        for X, y in train_dl:
            X, y = X.to(dev), y.to(dev)
            opt.zero_grad()
            l1_penalty = sum(torch.sum(torch.abs(p)) for p in m.parameters())
            out = m(X)
            loss = crit(out, y) + l1_lambda * l1_penalty
            loss.backward(); opt.step()
            ls += loss.item() * X.size(0)
            tot += y.size(0)
            corr += (out.argmax(1) == y).sum().item()
        epoch_loss = ls / tot
        epoch_acc = corr / tot
        history['loss'].append(epoch_loss)
        history['acc'].append(epoch_acc)
        print(f"[Manual-L1] Epoch {e+1}: Loss={epoch_loss:.4f}, Acc={epoch_acc:.4f}")
    return history

def compute_l1_norm(m):
    return sum(torch.sum(torch.abs(p)).item() for p in m.parameters())

# --- L1 Experiments ---
print("\n--- L1 Regularization via Proximal Gradient ---")
m_l1_prox = SimpleCNN()
opt_l1_prox = optim.Adam(m_l1_prox.parameters(), lr=0.001)
hist_l1_prox = train_l1_prox(m_l1_prox, tr_bas, vl_dl, crit, opt_l1_prox, epochs=5, l1_lambda=1e-4, dev=dev)

print("\n--- L1 Regularization via Manual Penalty ---")
m_l1_man = SimpleCNN()
opt_l1_man = optim.Adam(m_l1_man.parameters(), lr=0.001)
hist_l1_man = train_l1_manual(m_l1_man, tr_bas, vl_dl, crit, opt_l1_man, epochs=5, l1_lambda=1e-4, dev=dev)

# --- L1 Norms ---
l1_norm_prox = compute_l1_norm(m_l1_prox)
l1_norm_man = compute_l1_norm(m_l1_man)

# --- Final Metrics ---
val_acc_prox = hist_l1_prox['acc'][-1]
val_loss_prox = hist_l1_prox['loss'][-1]
val_acc_man = hist_l1_man['acc'][-1]
val_loss_man = hist_l1_man['loss'][-1]

print("\nFinal L1 Results:")
print(f"Proximal -> Val Acc: {val_acc_prox:.4f}, Val Loss: {val_loss_prox:.4f}, L1 Norm: {l1_norm_prox:.2f}")
print(f"Manual   -> Val Acc: {val_acc_man:.4f}, Val Loss: {val_loss_man:.4f}, L1 Norm: {l1_norm_man:.2f}")

# --- L1 Regularization Comparison Plot ---
fig, axs = plt.subplots(1, 3, figsize=(12, 4))
axs[0].bar(['Proximal', 'Manual'], [val_acc_prox, val_acc_man], color=['blue', 'orange'])
axs[0].set_ylabel('Val Accuracy'); axs[0].set_ylim(0, 1); axs[0].set_title('Val Accuracy')

axs[1].bar(['Proximal', 'Manual'], [val_loss_prox, val_loss_man], color=['blue', 'orange'])
axs[1].set_ylabel('Val Loss'); axs[1].set_title('Val Loss')

axs[2].bar(['Proximal', 'Manual'], [l1_norm_prox, l1_norm_man], color=['blue', 'orange'])
axs[2].set_ylabel('L1 Norm'); axs[2].set_title('L1 Norm')

plt.tight_layout()
plt.show()
===============================================================================================
